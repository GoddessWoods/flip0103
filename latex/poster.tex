%%
%% This is file `tikzposter-template.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% tikzposter.dtx  (with options: `tikzposter-template.tex')
%%
%% This is a generated file.
%%
%% Copyright (C) 2014 by Pascal Richter, Elena Botoeva, Richard Barnard, and Dirk Surmann
%%
%% This file may be distributed and/or modified under the
%% conditions of the LaTeX Project Public License, either
%% version 2.0 of this license or (at your option) any later
%% version. The latest version of this license is in:
%%
%% http://www.latex-project.org/lppl.txt
%%
%% and version 2.0 or later is part of all distributions of
%% LaTeX version 2013/12/01 or later.
%%


\documentclass{tikzposter} %Options for format can be included here

\usepackage{todonotes}

\usepackage[tikz]{bclogo}
\usepackage{lipsum}
\usepackage{amsmath}

\usepackage{booktabs}
\usepackage{longtable}
\usepackage[absolute]{textpos}
\usepackage[it]{subfigure}
\usepackage{graphicx}
\usepackage{cmbright}
%\usepackage[default]{cantarell}
%\usepackage{avant}
%\usepackage[math]{iwona}
\usepackage[math]{kurier}
\usepackage[T1]{fontenc}


%% add your packages here
\usepackage{hyperref}
% for random text
\usepackage{lipsum}
\usepackage[english]{babel}
\usepackage[pangram]{blindtext}

\colorlet{backgroundcolor}{blue!10}

 % Title, Author, Institute
\title{Group Outlying Aspects Mining}
\author{Shaoni Wang$^1$, Gang Li$^2$}
\institute{$^1$ Xi'an Shiyou University, China \\
	$^2$ Deakin University, Australia
}
%\titlegraphic{logos/tulip-logo.eps}

%Choose Layout
\usetheme{Wave}

%\definebackgroundstyle{samplebackgroundstyle}{
%\draw[inner sep=0pt, line width=0pt, color=red, fill=backgroundcolor!30!black]
%(bottomleft) rectangle (topright);
%}
%
%\colorlet{backgroundcolor}{blue!10}

\begin{document}


\colorlet{blocktitlebgcolor}{blue!23}

 % Title block with title, author, logo, etc.
\maketitle

\begin{columns}
 % FIRST column
\column{0.5}% Width set relative to text width

%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
 %\block{Main Objectives}{
%  	      	\begin{enumerate}
%  	      	\item Formalise research problem by extending \emph{outlying aspects mining}
%  	      	\item Proposed \emph{GOAM} algorithm is to solve research problem
%  	      	\item Utilise pruning strategies to reduce time complexity
%  	      	\end{enumerate}
%%  	      \end{minipage}
%}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block{Introduction}{
	Emotion detection has attracted great interest 
	in the natural language processing (NLP)
	in the last few years.
    affective states are generally represented 
    using either categorical or dimensional approaches.
    The most popular categorical approach represents is 
    Ekman’s six basic emotions 
    (e.g., anger, happiness, fear, sadness, disgust and surprise).
    Dimensional models consider affective states to
    be best described relative to a small number of
    independent emotional dimensions 
    (often two or three): 
    Valence 
    (a positive-negative scale), 
    Arousal 
    (a calm–excited scale)
    and Dominance 
    (perceived degree of control over a situation). 
    \begin{itemize}
    	\item Use Dimensional Emotions Distribution Learning
    	to predict multiple emotion dimension scores for an input text.
    	Then use the predicted VAD and notational VAD to 
    	do emotion classification.
    	\item Use TextCNN and LSTM netural network to 
    	do emotion classification.
    \end{itemize}
}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block{Data Set}{
Emobank corpus is composed of 
several categories of 
the Manually Annotated Sub-Corpus of the American National Corpus 
and the corpus of SemEval-2007 Task 14 Affective Text. 
MASC is already annotated on various linguistic levels. 
SE07, on the other hand, bears annotations according to 
Ekman’s six Basic Emotion on a [0,100] scale, respectively. 
Emobank contains 10,548 texts annotated with
Valence, Arousal and Dominance 
dimensional emotion scores, 
ranged from 1.0 to 5.0.

\begin{center}
	\begin{tabular}{cccc}
		\toprule
		Corpus & Domain  & Raw & Filtered  \\
		\midrule
		SE07 &  news headlines &  1250 &  1192 \\
		\hline
		&  blogs&  1378&  1336\\
		&  essays &  1196 &  1135 \\
		MASC&  fiction &  2893 &  2753 \\
		&  letters &  1479 &  1413 \\
		& newspapers & 1381 & 1314 \\
		& traval guides & 971 & 919 \\
		\bottomrule
	\end{tabular}
\end{center}
}

%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%

%\note{Note with default behavior}

%\note[targetoffsetx=12cm, targetoffsety=-1cm, angle=20, rotate=25]
%{Note \\ offset and rotated}

 % First column - second block


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block{DELD Algorithm}{
  	One sentence contain different scores of 
  	three dimensional emotions. 
  	We use $ d^y_{x} $ to indicate the intensity of 
  	dimensional emotion $ y $ for sentence $ x $, 
  	where $ x \in \chi  $ and $ y \in Y $.
  	The dimensional emotion intensity is needed to
  	meet the conditions that
  	$ d^y_{x} \in [0,1] $ and $\sum_{y}  d^y_{x} = 1$.
  	
  	Note that $ d^y_{x} $ denotes the proportion that 
  	$ y $ accounts for in a valence, 
  	arousal  and dominance dimensional emotion distribution
  	of $ x $.
  	
  	The training set is $ S = \{ ( x_{i} , D_{i} )  \}^{n}_{i=1} $,
  	where $ x_{i} \in \chi $ is a sentence embedding and
  	$ D_{i} = \{d^{y_{1}}_{x_{i}},  d^{y_{2}}_{x_{i}}, ... , d^{y_{c}}_{x_{i}}\} $
  	is the valence, arousal  and dominance dimensional emotion distribution.
  	The goal of DEDL is to 
  	learn a  conditional probability mass function $ p(y|x) $.
  	Assuming that $ p(y|x) $
  	is a parametric model $ p(y|x;{\theta}) $,
  	where $ \theta $ is model parameter.
  	
  	Use the Kullback-Leibler divergence	as 
  	the distance measure,
  	the best parameter vector $ \theta^{\ast} $ is determined by
  	
  	\begin{equation}\label{eq:kl_divergence}
  	\theta^{\ast} =
  	\mathop{\arg\min}\limits_{\theta}
  	\sum\limits_{i}
  	\sum\limits_{j}
  	(d^{y_{j}}_{ x_{ i } }
  	\ln \dfrac{ d^{y_{j}}_{ x_{ i } } }{ p( y_{ j } | x_{ i } ;{\theta}) })
  	\end{equation}
  	
  	Assumes the parametric model 
  	$ p(y|x;{\theta}) $ 
  	to be the maximum entropy model	
  	\begin{equation}
  		 p(y|x;{\theta}) = \dfrac{1}{Z}
  		\exp ( \sum\limits_{k}
  		{\theta}_{y,k} 
  		g_{k}( \textbf{x})  ) 
  	\end{equation}
  	
  	where $ Z = \sum _{y}
  	\sum_{k}  {\theta}_{y,k}  g_{k}( \textbf{x}) $
  	is a normalization factor,
  	$ {\theta}_{y,k} $ is an element in \textbf {$\theta$} ,
  	and $ g_{k}( \textbf{x}) $ is the \textit{k}-th feature of \textbf{ x }
  	
  	And for this problem,
  	the label distribution set $ D_{i} $ is that
  	$ D_{I} = \{d^{y_{v}}_{x_{i}},  d^{y_{a}}_{x_{i}}, d^{y_{d}}_{x_{i}}, d^{y_{n}}_{x_{i}}\} $,
  	where
  	$ d^{y_{v}}_{x_{i}} = \dfrac{score^{v}_{x_{i}}}{15} $,
  	$ d^{y_{v}}_{x_{i}} = \dfrac{score^{v}_{x_{i}}}{15} $,
  	$ d^{y_{v}}_{x_{i}} = \dfrac{score^{v}_{x_{i}}}{15} $,
  	and $ y_{n} = 1 - y_{v}  - y_{a} - y_{d} $.


\
}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


% SECOND column
\column{0.5}
 %Second column with first block's top edge aligned with with previous column's top.

%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block{TextCNN}{
The textCNN model mainly uses 
a one-dimensional convolutional layer and 
a max-over-time pooling layer. 
Assume that 
the input text sequence consists of $ n $ words, 
and each word is represented by 
a $ d  $dimensional word vector. 
Then the width of the input sample is$  n $, 
the height is 1, 
and the number of input channels is $ d $. 
The calculation of textCNN is mainly divided into the following steps.

\begin{itemize}
	\item 
	Define multiple one-dimensional convolution kernels, 
	and use these convolution kernels to 
	perform convolution calculations on the inputs. 
	\item 
	All the channels of the output are individually pooled 
	in max-over-time pooling, 
	and the pooled output values of 
	these channels are connected into a vector.
	\item 
	The fully connected layer transforms 
	the connected vectors into outputs for each class. 
	This step can use the dropout layer to deal with overfitting.
\end{itemize}
}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
% Second column - first block
\block{LSTM}{
	In the code I implement 
	\begin{itemize}
		\item 
		the Embedding instance is the embedding layer
		\item 
		the LSTM instance is the hidden layer of sequence encoding
		\item 
		the Linear instance is the output layer that generates the classification results
	\end{itemize}
}

%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block[titleleft]{Experiment}
{
\begin{description}
  	\item[Synthetic Dataset] contains $10$ groups and $8$ features.
    Each group consists of $10$ members,
    and each member has $8$ features.
\end{description}
\vspace{.5cm}
\begin{tabular}{ c | c | c | c }
    \toprule
    Method     &  Truth Outlying Aspects    & Identified Aspects & Accuracy      \\
    \midrule
    GOAM       &  $\{F_1\}$, $\{F_2F_4\}$   &  $\{F_1\}$, $\{F_2F_4\}$    & 100\%    \\

     Arithmetic Mean based OAM &  $\{F_1\}$, $\{F_2F_4\}$   &  $\{F_4\}$, $\{F_2\}$    &  0\% \\

     Median based OAM &  $\{F_1\}$, $\{F_2F_4\}$   &  $\{F_2\}$, $\{F_4\}$    &           0\% \\
     \bottomrule
\end{tabular}
\vspace{.2cm}
\begin{description}
    \item
    It can be observed that the GOAM method can identify the trivial outlying features
    and non-trivial outlying subspaces correctly and is obvious from the table
    that the accuracy of GOAM is the best, which is ($100\%$).
\end{description}

\begin{description}
\item[NBA Dataset] was collected from Yahoo Sports
website (\url{http://sports.yahoo.com.cn/nba}).
The data include all teams from the six divisions,
and each player in the team has $12$ features.
\end{description}
\vspace{.5cm}
\begin{tabular}{ c | c | c }
    \toprule
    Teams                   & Trivial Outlying Aspects  & NonTrivial Outlying Aspects    \\
    \toprule
    Cleveland Cavaliers     & \{3FA\}                   & \{FGA, FT\%\}, \{FGA, FG\%\} \\
    Orlando Magic           & \{Stl\}                   & None                         \\
    Milwaukee Bucks         & \{To\}, \{FTA\}           & \{FGA, FTA\}, \{3FA, FTA\}     \\
%    Golden State Warriors   & \{FG\%\}                  & \{FT\%, Blk\}, \{FGA, 3PT\%, FTA\}\\
%    Utah Jazz               & \{Blk\}                   & \{3FA, 3PT\%\}                    \\
    New Orleans Pelicans    & \{FT\%\}, \{FTA\}         & \{FTA, Stl\}, \{FTA, To\}          \\
    \bottomrule
\end{tabular}
           
\begin{minipage}{0.5\linewidth}
    \centering
    \begin{tikzfigure}
    \missingfigure[figcolor=white]{Testing figcolor}

    {\small{New Orleans Pelicans on FT\%}}
    \end{tikzfigure}%
\end{minipage}
\hfill
\begin{minipage}{0.5\linewidth}
    \centering
    \begin{tikzfigure}
    \missingfigure[figcolor=white]{Testing figcolor}

    {\small{New Orleans Pelicans on FTA}}
    \end{tikzfigure}%
\end{minipage}
\vspace{.2cm}
\begin{description}
\item
\texttt{New Orleans Pelicans} has more players with
lower \{free throw percentage\}, \{free throws attempted\}.
\end{description}
}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


% Second column - second block
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\block[titlewidthscale=1, bodywidthscale=1]
{Conclusion}
{
\begin{description}
  \item[Problem Definition]
  Formalize the problem of Group Outlying Aspects Mining by extending outlying aspects mining.

  \item[GOAM algorithm]
  Propose GOAM algorithm to solve the \emph{Group}\\
  \emph{Outlying Aspects Mining} problem.

  \item[Strategies]
  Utilize the pruning strategies to \\ reduce time complexity.
\end{description}
}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


% Bottomblock
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
\colorlet{notebgcolor}{blue!20}
\colorlet{notefrcolor}{blue!20}
\note[targetoffsetx=8cm, targetoffsety=-4cm, angle=30, rotate=15,
radius=2cm, width=.26\textwidth]{
Acknowledgement
\begin{itemize}
    \item
    International Cooperation Project (Y7Z0511101)
    of IIE,
    Chinese Academy of Sciences
 \end{itemize}
}

%\note[targetoffsetx=8cm, targetoffsety=-10cm,rotate=0,angle=180,radius=8cm,width=.46\textwidth,innersep=.1cm]{
%Acknowledgement
%}

%\block[titlewidthscale=0.9, bodywidthscale=0.9]
%{Acknowledgement}{
%}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%

\end{columns}


%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%
%[titleleft, titleoffsetx=2em, titleoffsety=1em, bodyoffsetx=2em,%
%roundedcorners=10, linewidth=0mm, titlewidthscale=0.7,%
%bodywidthscale=0.9, titlecenter]

%\colorlet{noteframecolor}{blue!20}
\colorlet{notebgcolor}{blue!20}
\colorlet{notefrcolor}{blue!20}
\note[targetoffsetx=-13cm, targetoffsety=-12cm,rotate=0,angle=180,radius=8cm,width=.96\textwidth,innersep=.4cm]
{
\begin{minipage}{0.3\linewidth}
\centering
\includegraphics[width=24cm]{logos/tulip-wordmark.eps}
\end{minipage}
\begin{minipage}{0.7\linewidth}
{ \centering
 The $11^{th}$ International Conference on Knowledge Science,
  Engineering and Management (KSEM 2018),
  17-19/08/2018, Changchun, China
}
\end{minipage}
}
%%%%%%%%%% -------------------------------------------------------------------- %%%%%%%%%%


\end{document}

%\endinput
%%
%% End of file `tikzposter-template.tex'.
